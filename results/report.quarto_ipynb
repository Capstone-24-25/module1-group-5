{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Biomarkers of ASD\"\n",
        "subtitle: \"If you want a subtitle put it here\"\n",
        "author: \"List names here\"\n",
        "date: last-modified\n",
        "published-title: \"Updated\"\n",
        "editor: visual\n",
        "format: html\n",
        "jupyter: python3\n",
        "code-copy: true\n",
        "execute:\n",
        "  message: false\n",
        "  warning: false\n",
        "  echo: false\n",
        "  cache: true\n",
        "---\n",
        "\n",
        "\n",
        "Use this as a template. Keep the headers and remove all other text. In all, your report can be quite short. When it is complete, render and then push changes to your team repository.\n",
        "\n",
        "\n",
        "```{r}\n",
        "# load any other packages and read data here\n",
        "library(tidyverse)\n",
        "library(reticulate)\n",
        "library(ggplot2)\n",
        "library(dplyr)\n",
        "library(gridExtra)\n",
        "library(readr)\n",
        "\n",
        "# uncomment the line to download python modules\n",
        "# py_install(c('pandas', 'numpy', 'sklearn', 'matplotlib'))\n",
        "```"
      ],
      "id": "63d24332"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| label: setup\n",
        "#| echo: false\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score, confusion_matrix\n",
        "from matplotlib import pyplot as plt\n",
        "import pickle\n",
        "\n",
        "with open('../data/q4_variables.pkl', 'rb') as f:\n",
        "  q4_variables = pickle.load(f)\n",
        "  \n",
        "biomarker_rfe_top10_x = q4_variables['biomarker_rfe_top10_x'] \n",
        "biomarker_rfe_top10_y =  q4_variables['biomarker_rfe_top10_y']\n",
        "biomarker_rfe_top10_names = q4_variables['biomarker_rfe_top10_names']\n",
        "offset_index = q4_variables['offset_index']\n",
        "label_x = q4_variables['label_x']\n",
        "label_y = q4_variables['label_y']\n",
        "biomarker_name = q4_variables['biomarker_name']\n",
        "offsets_1 = q4_variables['offsets_1']\n",
        "ranking_sorted = q4_variables['ranking_sorted']\n",
        "x_axis = q4_variables['x_axis']\n",
        "y_axis = q4_variables['y_axis']\n",
        "fi_rf_sorted = q4_variables['fi_rf_sorted']"
      ],
      "id": "setup",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Abstract\n",
        "\n",
        "Write a brief one-paragraph abstract that describes the contents of your write-up.\n",
        "\n",
        "## Dataset\n",
        "\n",
        "This data contains information on whether or not boys from the age of 18 months to 8 years have Autism Spectrum Disorder (ASD) and their protein serum samples. There were a total 154 boys measured through blood collection and SomaLogic analysis, with 76 being diagnosed with ASD and 78 in the typically developing (TD) group. The mean ages for these groups were 5.6 and 5.7 years respectively with standard deviations of 1.7 and 2.0 years. There were 73 Caucasian, 32 Hispanic/Latino, 17 African American/Black, 5 Asian or Pacific Islander, 23 multiple ethnicities or other, and 4 not reported subjects in the dataset. Comorbidities were measured and it was found that 75.3% of TD boys and 52.8% of ASD boys had no comorbidities and the next most common was seasonal allergies which 41.7% of ASD boys had and 22.4% of TD boys had. In addition, the ASD group underwent assessment from a clinical psychologist to obtain an Autism Diagnostic Observation Schedule (ADOS) score, which provides a continuous measure of overall ASD symptom severity. A total of 1,317 proteins were measured, but 192 failed the quality control test so 1,125 proteins were analyzed. Of the 1,125 proteins, that data was normalized by taking a log 10 transform and then a z-transformation. For more preprocessing, to deal with outliers, any z-transformed values outside the range of -3 to 3 were clipped to -3 and 3, respectively.\n",
        "\n",
        "## Summary of published analysis\n",
        "\n",
        "<!-- Summarize the methodology of the paper in 1-3 paragraphs. You need not explain the methods in depth as we did in class; just indicate what methods were used and how they were combined. If possible, include a diagram that depicts the methodological design. (Quarto has support for [GraphViz and Mermaid flowcharts](https://quarto.org/docs/authoring/diagrams.html).) Provide key results: the proteins selected for the classifier and the estimated accuracy. -->\n",
        "\n",
        "Our goal is to find a protein panel that can best predict if levels of expression of them can be used to predict if a person has Autism.\n",
        "\n",
        "General Steps:\n",
        "\n",
        "-   Remove the bio-marker that is highly correlated with each other with the threshold `> 0.9`.\n",
        "\n",
        "-   Apply backwards selection using L1 logistic regression to select top 20 features based on feature importance.\n",
        "\n",
        "-   Apply random forest with 5 folds cross validation to select top 20 features based on the average feature importance\n",
        "\n",
        "-   Union the 40 features to use them as the base model, apply backwards selection using elastic net logistic regression (50% L1 and 50% L2) to select a protein panel with 9 bio-markers\n",
        "\n",
        "-   Fit the final model using L1 logistic regression of 6 bio-markers and achieve the ROC-AUC value of 87.29%\n",
        "\n",
        "::: {style=\"display: flex; justify-content: center;\"}\n",
        "\n",
        "```{mermaid}\n",
        "flowchart TB\n",
        "classDef default scale:1;\n",
        "  A[Original Cleaned Sample] --> B[Correlation Feature Selection]\n",
        "  B --> C[L1 Logistic Regression<br>Recursive Feature Elimination]\n",
        "  B --> D[Random Forest<br>5 Folds Cross Validation]\n",
        "  C --> E[Union the Candidates]\n",
        "  D --> E[Union the Candidates]\n",
        "  E --> F[Elastic Net Logistic Regression<br>Recursive Feature Elimination]\n",
        "  F --> G[Final 6-Protein Panel]\n",
        "  G --> H(L1 Logistic Regression<br>Consturct Final Model for Testing)\n",
        "```\n",
        "\n",
        ":::\n",
        "\n",
        "### L1 logistic regression - Recursive Feature Elimination\n",
        "\n",
        "Logistic Regression is used for the second round of selection. The L1 Lasso Regularization is used to select the bio-markers from the total 1194 bio-markers (after dropping the bio-markers with high correlation). L1 Regularization penalizes the features with the least absolute coefficients, or weights, in the logit, and eventually drives them to zero. Those ones are bio-markers that are considered to be less important. We select total 20 candidates with the highest rank. Top ten bio-markers are plotted for neat visualization purpose.\n"
      ],
      "id": "738c578a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fig, ax = plt.subplots(figsize=[10, 6]);\n",
        "plt.scatter(x=x_axis, y=y_axis, s=1);\n",
        "\n",
        "for x, y, name, idx in zip(biomarker_rfe_top10_x, biomarker_rfe_top10_y, biomarker_rfe_top10_names, offset_index):\n",
        "  ax.scatter(biomarker_rfe_top10_x, biomarker_rfe_top10_y, c='red', s=1);\n",
        "\n",
        "  offset_x = 40 if idx <= 10 else None\n",
        "  offset_y = (idx % 10) * 12 + 50\n",
        "\n",
        "  ax.annotate(\n",
        "    f'{name}' if idx <= 10 else None,\n",
        "    (x, y),\n",
        "    textcoords='offset points',\n",
        "    xytext=(offset_x, offset_y),\n",
        "    fontsize=6,\n",
        "    ha='center',\n",
        "    color='black',\n",
        "    bbox=dict(boxstyle='round,pad=0.3', edgecolor='black', facecolor='white', alpha=0.5) if idx <= 10 else None,\n",
        "    arrowprops=dict(arrowstyle='-', color='grey', linewidth=0.5) if idx <= 10 else None\n",
        "  )\n",
        "\n",
        "ax.set_xticks(ticks=());\n",
        "ax.set_xlabel('Protein');\n",
        "ax.set_ylabel('Ranks (Feature Importance)');\n",
        "ax.set_title('Recursive Feature Elimination - L1 Logistic Regression')\n",
        "  \n",
        "plt.show();"
      ],
      "id": "bc787cd9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Random Forest - 5 folds Cross Validation\n",
        "\n",
        "Random forest Algorithm is applied for the third round of selection. The Gini Importance, or the mean decrease in impurity, is used as the metric to determine the contribution of each bio-marker in predicting the outcome. The feature importance for each feature is computed by averaging the total impurity decrease across all the trees in the forest where the feature is used. Another 20 bio-markers are identified as candidates for final selection. The plot demonstrated the top 10 bio-markers which have the highest log average feature importance.\n",
        "\n",
        "We then union two sets of candidates to serve as the pool of our final selection.\n"
      ],
      "id": "601b42a6"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fig, ax = plt.subplots(figsize=[10, 6])\n",
        "ax.scatter(x=range(1194), y=fi_rf_sorted, s=1, alpha=0.8);\n",
        "\n",
        "for x, y, name, idx in zip(label_x, label_y, biomarker_name, offsets_1):\n",
        "  offset_x = -60 if idx >= 10 else 0  # Labels for first 10 points to the left, next 10 to the right\n",
        "  offset_y = (idx % 10) * 10 - 90     # Stagger labels vertically to prevent overlap\n",
        "\n",
        "  ax.scatter(x, y, c='red', s=1);\n",
        "  ax.annotate(\n",
        "    f'{name}' if idx >= 10 else None,\n",
        "    (x, y),\n",
        "    textcoords='offset points',\n",
        "    xytext=(offset_x, offset_y),\n",
        "    ha='center',\n",
        "    fontsize=6,\n",
        "    color='black',\n",
        "    bbox=dict(boxstyle='round,pad=0.3', edgecolor='black', facecolor='white', linewidth=0.5, alpha=0.5),\n",
        "    arrowprops=dict(arrowstyle=\"-\", color='gray', lw=0.5) if idx >= 10 else None\n",
        "  )\n",
        "\n",
        "ax.set_xticks(ticks=());\n",
        "ax.set_xlabel('Proteins')\n",
        "ax.set_ylabel('log Average of 5 folds Feature Importance')\n",
        "ax.set_title('Feature Importance of Random Forest - 5 Folds CV')\n",
        "\n",
        "plt.show();"
      ],
      "id": "ab73cf7c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Elastic Net Logistic Regression - Recursive Feature Elimination\n",
        "\n",
        "50% of L1 regularization and 50% of L2 regularization is applied on the Elastic Net Logistic Regression to recursively select bio-markers with each step, finding a 6 bio-markers protein panel which has the best predictive power. While L1 penalization shrinks the least absolute value of coefficients to zero, L2 handles the multicollinearity by distributing importance across correlated features.\n",
        "\n",
        "## Findings\n",
        "\n",
        "### Impact of preprocessing and outliers\n",
        "\n",
        "\n",
        "```{r}\n",
        "biomarker_raw <- read.csv('../data/biomarker-raw.csv')\n",
        "biomarker_num <- biomarker_raw[-1,]\n",
        "biomarker_num <- biomarker_num %>% mutate_all(~ as.numeric(as.character(.)))\n",
        "\n",
        "p11 <- ggplot(biomarker_num, aes(x = Gamma.enolase)) +\n",
        "  geom_histogram(bins = 15)\n",
        "p21 <- ggplot(biomarker_num, aes(x = E3.ubiquitin.protein.ligase.CHIP)) +\n",
        "  geom_histogram(bins = 10)\n",
        "p31 <- ggplot(biomarker_num, aes(x = CCAAT.enhancer.binding.protein.beta)) +\n",
        "  geom_histogram(bins = 15)\n",
        "p41 <- ggplot(biomarker_num, aes(x = Vitronectin)) +\n",
        "  geom_histogram(bins = 20)\n",
        "p51 <- ggplot(biomarker_num, aes(x = Histone.H3.1)) +\n",
        "  geom_histogram(bins = 15)\n",
        "p61 <- ggplot(biomarker_num, aes(x = Semaphorin.5A)) +\n",
        "  geom_histogram(bins = 20)\n",
        "p71 <- ggplot(biomarker_num, aes(x = Protein.S100.A6)) +\n",
        "  geom_histogram(bins = 15)\n",
        "\n",
        "p12 <- ggplot(biomarker_num, aes(x = log(Gamma.enolase))) +\n",
        "  geom_histogram(bins = 15)\n",
        "p22 <- ggplot(biomarker_num, aes(x = log(E3.ubiquitin.protein.ligase.CHIP))) +\n",
        "  geom_histogram(bins = 10)\n",
        "p32 <- ggplot(biomarker_num, aes(x = log(CCAAT.enhancer.binding.protein.beta))) +\n",
        "  geom_histogram(bins = 15)\n",
        "p42 <- ggplot(biomarker_num, aes(x = log(Vitronectin))) +\n",
        "  geom_histogram(bins = 20)\n",
        "p52 <- ggplot(biomarker_num, aes(x = log(Histone.H3.1))) +\n",
        "  geom_histogram(bins = 15)\n",
        "p62 <- ggplot(biomarker_num, aes(x = log(Semaphorin.5A))) +\n",
        "  geom_histogram(bins = 20)\n",
        "p72 <- ggplot(biomarker_num, aes(x = log(Protein.S100.A6))) +\n",
        "  geom_histogram(bins = 15)\n",
        "\n",
        "grid.arrange(p11, p12,  ncol = 2)\n",
        "grid.arrange(p21, p22,  ncol = 2)\n",
        "grid.arrange(p31, p32,  ncol = 2)\n",
        "grid.arrange(p41, p42,  ncol = 2)\n",
        "grid.arrange(p51, p52,  ncol = 2)\n",
        "grid.arrange(p61, p62,  ncol = 2)\n",
        "grid.arrange(p71, p72,  ncol = 2)\n",
        "```\n",
        "\n",
        "\n",
        "To begin with the preprocessing of the data, we first look at the raw proteins to see how they are distributed. From observing the distribution of a sample of the proteins from the raw file, it is clear that many of them have skewed distributions. These skewed distributions could be due to high variability in the protein levels which leads to outliers that are affecting our data and predictions. To improve our model and predictions, we can log transform the proteins to help normalize the distributions. By doing this, it helps to improve our models performance since machine learning techniques like random forest will give you better predictions when the input data is more normally distributed. As we can observe from the difference in the raw and the log transformed histograms for this sample of proteins, the transformation helps to normalize the distributions of the raw proteins in our dataset.\n",
        "\n",
        "\n",
        "```{r}\n",
        "var_names <- read_csv('../data/biomarker-raw.csv', # prevent interpreting the first row as header \n",
        "                      n_max = 2, # read only 2 rows\n",
        "                      col_names = F,  # exclude first two columns\n",
        "                      col_select = -(1:2) ) %>%  # switching rows and columns\n",
        "  t() %>% as_tibble() %>% \n",
        "  rename( name = V1, abbreviation = V2 ) %>% # name, abbreviate are the new name. V1, V2 are the the default old names\n",
        "  na.omit()\n",
        "```\n",
        "\n",
        "\n",
        "# read in data\n",
        "\n",
        "\n",
        "```{r}\n",
        "biomarker_clean <- read_csv(\"../data/biomarker-raw.csv\",\n",
        "                            skip = 2,\n",
        "                            col_select = -2L,\n",
        "                            col_names = c(\n",
        "                              \"group\",\n",
        "                              \"empty\",\n",
        "                              pull(var_names, abbreviation),\n",
        "                              \"ados\"\n",
        "                            ),\n",
        "                            # Treat '-' and '' as NA.\n",
        "                            na = c(\"-\", \"\")\n",
        ") %>%\n",
        "  filter(!is.na(group)) %>%\n",
        "  mutate(across(\n",
        "    .cols = -c(group, ados),\n",
        "    ~ scale(log10(.x))[, 1]\n",
        "  )) %>%\n",
        "  select(group, ados, everything())\n",
        "\n",
        "outlier_threshold <- 3 \n",
        "outlier_df <- biomarker_clean %>%\n",
        "  mutate(across(\n",
        "    .cols = -c(group, ados),  \n",
        "    ~ ifelse(abs(.) > outlier_threshold, ., NA) \n",
        "  ))\n",
        "\n",
        "outlier_summary <- outlier_df %>%\n",
        "  select(group, ados, everything()) %>%\n",
        "  pivot_longer(-c(group, ados), names_to = \"biomarker\", values_to = \"value\") %>%\n",
        "  filter(!is.na(value)) %>%  # Keep only outliers\n",
        "  group_by(group, ados, biomarker) %>%\n",
        "  summarise(count = n(), .groups = \"drop\") %>%\n",
        "  filter(count > 2)\n",
        "\n",
        "view(outlier_summary)\n",
        "```\n",
        "\n",
        "\n",
        "If we examine the outlier_summary table, it shows us the biomarkers that have an outlier point as well as the group and ados score for the subject that corresponds to that outlier point. Overall, there are 1822 biomarkers which have at least 1 outlying point. Attempting to identify individual subjects we can filter to only see biomarkers which have an outlier count of 1. Doing this, we see ados values ranging from 6-23 as well as NA. Each of these 18 unique ados values likely correspond to an individual outlying subject that has many outlying biomarkers. There are 449 outlying biomarkers which correspond to a subject which is typically developing, while there are 922 biomarkers which correspond to a subject which is autistic. With this, we can conclude that it's more likely for an autistic subject to be an outlier subject than it is for those which are typically developing.\n",
        "\n",
        "### Methodlogical variations\n",
        "\n",
        "Task 3\n",
        "\n",
        "### Improved classifier\n",
        "\n",
        "The final protein panel is made of 6 bio-markers showed below:\n"
      ],
      "id": "046fcef0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "with open('../data/q4_variables.pkl', 'rb') as f:\n",
        "  q4_variables = pickle.load(f)\n",
        "  \n",
        "protein_panel_name = q4_variables['protein_panel_name']\n",
        "\n",
        "panel = ''\n",
        "for biomarker in protein_panel_name:\n",
        "  panel += biomarker + ', '\n",
        "\n",
        "print(panel[:-3])"
      ],
      "id": "1e0d86f2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We use the ROC-AUC metric for testing. Our approach simplifies the original 9-biomarkers panel to 6 while yielding a comparable predictive power. It can be interpreted as that the possibility of ranking a randomly chosen ASD patient higher than the possibility of ranking a randomly chosen TD patient. \n",
        "\n",
        "The confusion matrix is plotted below\n"
      ],
      "id": "27c618ef"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "cm = np.loadtxt('../../data/confusion_matrix.csv', delimiter=',')\n",
        "fig, ax = plt.subplots(figsize=[8, 8])\n",
        "ax.imshow(cm, cmap=\"Blues\")\n",
        "ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted TD', 'Predicted ASD'))\n",
        "ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual TD', 'Actual ASD'))\n",
        "for i in range(2):\n",
        "  for j in range(2):\n",
        "    ax.text(j, i, cm[i, j], ha='center', va='center', color='black', fontdict={'fontsize': 20})\n",
        "ax.grid(False)\n",
        "ax.set_title('Confusion Matrix of Final Predictions')\n",
        "plt.show();"
      ],
      "id": "6135d3f4",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/Users/jaxonz/.virtualenvs/r-reticulate/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}